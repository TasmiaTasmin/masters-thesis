{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Algorithms - Experiments - Chapter 5 and 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List, Optional\n",
    "from shapely.geometry import Polygon, MultiPolygon, Point\n",
    "\n",
    "from experimental.utils.dynamic_system import DynamicSystem\n",
    "from experimental.utils.markov_decision_process import MarkovDecisionProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define System Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,1], [1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x: np.array) -> np.array:\n",
    "    x_new = np.dot(A, x) % 1\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(x: np.array) -> np.array:\n",
    "    return x % 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get eigenvalues and right eigenvectors, i.e. transposed eigenvectors\n",
    "eig_vals, eig_vects = np.linalg.eig(A)\n",
    "# retrieve eigenvectors from right eigenvectors\n",
    "eig_vects = np.transpose(eig_vects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Eigenvalues: {eig_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Eigenvectors: {eig_vects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = eig_vects[0]\n",
    "v2 = eig_vects[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Inetrsection Points between Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perp(a) :\n",
    "    b = np.empty_like(a)\n",
    "    b[0] = -a[1]\n",
    "    b[1] = a[0]\n",
    "    return b\n",
    "\n",
    "# line segment a given by endpoints a1, a2\n",
    "# line segment b given by endpoints b1, b2\n",
    "def seg_intersect(a, b) :\n",
    "    a1, a2 = a\n",
    "    b1, b2 = b\n",
    "\n",
    "    da = a2 - a1\n",
    "    db = b2 - b1\n",
    "    dp = a1 - b1\n",
    "    dap = perp(da)\n",
    "    denom = np.dot(dap, db)\n",
    "    num = np.dot(dap, dp)\n",
    "\n",
    "    return (num / denom.astype(float))*db + b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Markov Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = np.array([0,0])\n",
    "u2 = np.array([0,1])\n",
    "u3 = np.array([1,1])\n",
    "u4 = np.array([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu1 = np.array([[0,0], [0,1]])\n",
    "lu2 = np.array([[0,1], [1,1]])\n",
    "lu3 = np.array([[1,1], [1,0]])\n",
    "lu4 = np.array([[1,0], [0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = u1 + (1/v1[0]) * v1\n",
    "p2 = u2 - (1/v2[1]) * v2\n",
    "p3 = u3 - (1/v1[0]) * v1\n",
    "p4 = u4 + (1/v2[1]) * v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_00 = np.array([u1, p1])\n",
    "l_01 = np.array([u2, p2])\n",
    "l_10 = np.array([u4, p4])\n",
    "l_11 = np.array([u3, p3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1a = seg_intersect(l_00, l_01)\n",
    "P1b = seg_intersect(l_10, l_00)\n",
    "\n",
    "P3a = seg_intersect(l_10, l_11)\n",
    "\n",
    "symm_helper_x = seg_intersect(lu2, l_10)\n",
    "symm_helper_y = symm_helper_x - np.array([0,1])\n",
    "symm_helper_l11 = np.array([symm_helper_x, symm_helper_y])\n",
    "\n",
    "p1_symm = symm_helper_y + v2\n",
    "l_10_symm_extension = np.array([symm_helper_y, p1_symm])\n",
    "P3b = seg_intersect(l_10_symm_extension, l_00)\n",
    "l_10_symm_extension = np.array([symm_helper_y, P3b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_00 = np.array([u1, P1b])\n",
    "l_01 = np.array([u2, P1a])\n",
    "l_10 = np.array([u4, p4])\n",
    "l_11 = np.array([u3, P3a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot unit square\n",
    "plt.plot(lu1[:, 0], lu1[:, 1], \"r-\")\n",
    "plt.plot(lu2[:, 0], lu2[:, 1], \"r-\")\n",
    "plt.plot(lu3[:, 0], lu3[:, 1], \"r-\")\n",
    "plt.plot(lu4[:, 0], lu4[:, 1], \"r-\")\n",
    "\n",
    "# step 1: plot l_10 in contracting direction\n",
    "plt.plot(l_10[:, 0], l_10[:, 1], \"b-\")\n",
    "\n",
    "# step 2: plot l_00 and l_11 in expanding directions\n",
    "plt.plot(l_00[:, 0], l_00[:, 1], \"b-\")\n",
    "plt.plot(l_11[:, 0], l_11[:, 1], \"b-\")\n",
    "\n",
    "# step 3: plot l_01 in contracting direction \n",
    "plt.plot(l_01[:, 0], l_01[:, 1], \"b-\")\n",
    "\n",
    "# step 4: plot symmetric extension of l_01 line\n",
    "plt.plot(symm_helper_l11[:, 0], symm_helper_l11[:, 1], \"m--\")\n",
    "plt.plot(l_10_symm_extension[:, 0], l_10_symm_extension[:, 1], \"b-\")\n",
    "\n",
    "# plot intersection points\n",
    "plt.plot(P1a[0], P1a[1], \"bo\")\n",
    "plt.plot(P1b[0], P1b[1], \"ro\")\n",
    "plt.plot(P3a[0], P3a[1], \"go\")\n",
    "plt.plot(P3b[0], P3b[1], \"yo\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Partition to Shapely-Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1A = Polygon([P1a, u1, u2])\n",
    "P1B = Polygon([P3a, u3, u4])\n",
    "P1 = MultiPolygon([P1A, P1B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P2A = Polygon([P3b, u1, symm_helper_l11[1]])\n",
    "P2B = Polygon([symm_helper_l11[0], u2, P1a, P1b])\n",
    "P2 = MultiPolygon([P2A, P2B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P3A = Polygon([P1b, u4, symm_helper_l11[1], P3b])\n",
    "P3B = Polygon([symm_helper_l11[0], u3, P3a])\n",
    "P3 = MultiPolygon([P3A, P3B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = [P1, P2, P3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiPolygon([P1A, P1B, P2A, P2B, P3A, P3B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1A_phi = Polygon([P1b, u4, u1])\n",
    "P1B_phi = Polygon([u2, u3, phi(P3a)])\n",
    "P1_phi = MultiPolygon([P1A_phi, P1B_phi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symm_helper_x = seg_intersect(lu3, l_00)\n",
    "symm_helper_y = q(symm_helper_x)\n",
    "symm_helper_l00 = np.array([symm_helper_x, symm_helper_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P2A_phi = Polygon([symm_helper_l00[1], phi(P1b), P1a, u1])\n",
    "P2B_phi = Polygon([symm_helper_l00[0], u4, P1b])\n",
    "P2_phi = MultiPolygon([P2A_phi, P2B_phi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P3A_phi = Polygon([phi(P3a), P1a, symm_helper_l00[0], u3])\n",
    "P3B_phi = Polygon([u2, phi(P1b), symm_helper_l00[1]])\n",
    "P3_phi = MultiPolygon([P3A_phi, P3B_phi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiPolygon([P1A_phi, P1B_phi, P2A_phi, P2B_phi, P3A_phi, P3B_phi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_phi = [P1_phi, P2_phi, P3_phi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Monte Carlo Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_non_identified(x: np.array) -> np.array:\n",
    "    return np.dot(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_phi(x: np.array) -> np.array:\n",
    "    return np.transpose(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_id = 1\n",
    "dynamic_system = DynamicSystem(phi_non_identified, d_phi, m_id)\n",
    "markov_decision_process = MarkovDecisionProcess(dynamic_system, partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_decision_process.estimate_probability_matrix_pi_method(c=1000, tau=0.001, max_sample_trials=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_decision_process.estimate_probability_matrix_random_walker_method(l=50, m=1000, max_sample_trials=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Probability Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_mat_ground_truth = markov_decision_process.ground_truth_probability_matrix(partition_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_mat_ground_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments - Monte Carlo Algorithm Random Walk Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_candidates = list(np.ceil(np.linspace(start=1, stop=300, num=20)))\n",
    "l_candidates = list(np.ceil(np.linspace(start=1, stop=100, num=20)))\n",
    "repetitions = 10\n",
    "compute_experiments = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_experiments:\n",
    "    estimation_error = {}\n",
    "    for m_candidate in m_candidates:\n",
    "        estimation_error[m_candidate] = {}\n",
    "        for l_candidate in l_candidates:\n",
    "            estimation_error[m_candidate][l_candidate] = {}\n",
    "            for i in range(repetitions):\n",
    "                rep_key = f\"rep_{i+1}\"\n",
    "                estimation_error[m_candidate][l_candidate][rep_key] = {}\n",
    "                print(f\"m={m_candidate}, l={l_candidate}, Rep: {i+1}\")\n",
    "\n",
    "                start_time = time.time()\n",
    "                prob_mat_estimated = markov_decision_process.estimate_probability_matrix_random_walker_method(l=l_candidate, m=m_candidate, max_sample_trials=1000)\n",
    "                end_time = time.time()\n",
    "                run_time = round(end_time - start_time, 2)\n",
    "\n",
    "                estimation_error[m_candidate][l_candidate][rep_key][\"mean\"] = np.mean(np.abs(prob_mat_estimated - prob_mat_ground_truth))\n",
    "                estimation_error[m_candidate][l_candidate][rep_key][\"sum\"] = np.sum(np.abs(prob_mat_estimated - prob_mat_ground_truth))\n",
    "                estimation_error[m_candidate][l_candidate][rep_key][\"median\"] = np.median(np.abs(prob_mat_estimated - prob_mat_ground_truth))\n",
    "                estimation_error[m_candidate][l_candidate][rep_key][\"max\"] = np.max(np.abs(prob_mat_estimated - prob_mat_ground_truth))\n",
    "                estimation_error[m_candidate][l_candidate][rep_key][\"run_time\"] = run_time\n",
    "\n",
    "                print(f\"Estimation error measures: {estimation_error[m_candidate][l_candidate][rep_key]} \\n\")\n",
    "\n",
    "    with open(f\"results/estimate_prob_random_walk_method.pkl\", \"wb\") as file:\n",
    "        pickle.dump(estimation_error, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(f\"results/estimate_prob_random_walk_method.pkl\", \"rb\") as file:\n",
    "        estimation_error = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_error_averaged = {}\n",
    "for m_candidate in m_candidates:\n",
    "    estimation_error_averaged[m_candidate] = {}\n",
    "    for l_candidate in l_candidates:\n",
    "        estimation_error_averaged[m_candidate][l_candidate] = {}\n",
    "\n",
    "        means = np.zeros(repetitions)\n",
    "        sums = np.zeros(repetitions)\n",
    "        medians = np.zeros(repetitions)\n",
    "        maxs = np.zeros(repetitions)\n",
    "        run_times = np.zeros(repetitions)\n",
    "\n",
    "        for i in range(repetitions):\n",
    "            rep_key = f\"rep_{i+1}\"\n",
    "            means[i] = estimation_error[m_candidate][l_candidate][rep_key][\"mean\"]\n",
    "            sums[i] = estimation_error[m_candidate][l_candidate][rep_key][\"sum\"]\n",
    "            medians[i] = estimation_error[m_candidate][l_candidate][rep_key][\"median\"]\n",
    "            maxs[i] = estimation_error[m_candidate][l_candidate][rep_key][\"max\"]\n",
    "            run_times[i] = estimation_error[m_candidate][l_candidate][rep_key][\"run_time\"]\n",
    "\n",
    "        estimation_error_averaged[m_candidate][l_candidate][\"mean\"] = {\"avg\": np.mean(means), \"var\": np.var(means)}\n",
    "        estimation_error_averaged[m_candidate][l_candidate][\"sum\"] = {\"avg\": np.mean(sums), \"var\": np.var(sums)}\n",
    "        estimation_error_averaged[m_candidate][l_candidate][\"median\"] = {\"avg\": np.mean(medians), \"var\": np.var(medians)}\n",
    "        estimation_error_averaged[m_candidate][l_candidate][\"max\"] = {\"avg\": np.mean(maxs), \"var\": np.var(maxs)}\n",
    "        estimation_error_averaged[m_candidate][l_candidate][\"run_time\"] = {\"avg\": np.mean(run_times), \"var\": np.var(run_times)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_l = 1\n",
    "medium_l = 12\n",
    "large_l = 54\n",
    "\n",
    "small_tau_m_mean_errors = {}\n",
    "medium_tau_m_mean_errors = {}\n",
    "large_tau_m_mean_errors = {}\n",
    "\n",
    "small_tau_m_sum_errors = {}\n",
    "medium_tau_m_sum_errors = {}\n",
    "large_tau_m_sum_errors = {}\n",
    "\n",
    "small_tau_m_max_errors = {}\n",
    "medium_tau_m_max_errors = {}\n",
    "large_tau_m_max_errors = {}\n",
    "\n",
    "small_tau_m_run_times = {}\n",
    "medium_tau_m_run_times = {}\n",
    "large_tau_m_run_times = {}\n",
    "\n",
    "for m in m_candidates:\n",
    "    small_tau_m_mean_errors[m] = estimation_error_averaged[m][small_l][\"mean\"][\"avg\"]\n",
    "    medium_tau_m_mean_errors[m] = estimation_error_averaged[m][medium_l][\"mean\"][\"avg\"]\n",
    "    large_tau_m_mean_errors[m] = estimation_error_averaged[m][large_l][\"mean\"][\"avg\"]\n",
    "\n",
    "    small_tau_m_sum_errors[m] = estimation_error_averaged[m][small_l][\"sum\"][\"avg\"]\n",
    "    medium_tau_m_sum_errors[m] = estimation_error_averaged[m][medium_l][\"sum\"][\"avg\"]\n",
    "    large_tau_m_sum_errors[m] = estimation_error_averaged[m][large_l][\"sum\"][\"avg\"]\n",
    "\n",
    "    small_tau_m_max_errors[m] = estimation_error_averaged[m][small_l][\"max\"][\"avg\"]\n",
    "    medium_tau_m_max_errors[m] = estimation_error_averaged[m][medium_l][\"max\"][\"avg\"]\n",
    "    large_tau_m_max_errors[m] = estimation_error_averaged[m][large_l][\"max\"][\"avg\"]\n",
    "\n",
    "    small_tau_m_run_times[m] = estimation_error_averaged[m][small_l][\"run_time\"][\"avg\"]\n",
    "    medium_tau_m_run_times[m] = estimation_error_averaged[m][medium_l][\"run_time\"][\"avg\"]\n",
    "    large_tau_m_run_times[m] = estimation_error_averaged[m][large_l][\"run_time\"][\"avg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(small_tau_m_mean_errors.keys(), small_tau_m_mean_errors.values(), color=\"blue\", label=f\"l = {small_l}\")\n",
    "plt.plot(medium_tau_m_mean_errors.keys(), medium_tau_m_mean_errors.values(), color=\"green\", label=f\"l = {medium_l}\")\n",
    "plt.plot(large_tau_m_mean_errors.keys(), large_tau_m_mean_errors.values(), color=\"red\", label=f\"l = {large_l}\")\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Candidates parameter m\")\n",
    "plt.ylabel(\"MEAN_ERROR\")\n",
    "plt.title(\"Mean error per state transistion probability estimate\")\n",
    "\n",
    "plt.savefig(\"results/plots/mean_error_random_walker.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(small_tau_m_sum_errors.keys(), small_tau_m_sum_errors.values(), color=\"blue\", label=f\"l = {small_l}\")\n",
    "plt.plot(medium_tau_m_sum_errors.keys(), medium_tau_m_sum_errors.values(), color=\"green\", label=f\"l = {medium_l}\")\n",
    "plt.plot(large_tau_m_sum_errors.keys(), large_tau_m_sum_errors.values(), color=\"red\", label=f\"l = {large_l}\")\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Candidates parameter m\")\n",
    "plt.ylabel(\"SUM_ERROR\")\n",
    "plt.title(\"Sum of estimation errors over all transitions\")\n",
    "\n",
    "plt.savefig(\"results/plots/sum_error_random_walker.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(small_tau_m_max_errors.keys(), small_tau_m_max_errors.values(), color=\"blue\", label=f\"l = {small_l}\")\n",
    "plt.plot(medium_tau_m_max_errors.keys(), medium_tau_m_max_errors.values(), color=\"green\", label=f\"l = {medium_l}\")\n",
    "plt.plot(large_tau_m_max_errors.keys(), large_tau_m_max_errors.values(), color=\"red\", label=f\"l = {large_l}\")\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Candidates parameter m\")\n",
    "plt.ylabel(\"MAX_ERROR\")\n",
    "plt.title(\"Max of estimation errors over all transitions\")\n",
    "\n",
    "plt.savefig(\"results/plots/max_error_random_walker.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(small_tau_m_run_times.keys(), small_tau_m_run_times.values(), color=\"blue\", label=f\"l = {small_l}\")\n",
    "plt.plot(medium_tau_m_run_times.keys(), medium_tau_m_run_times.values(), color=\"green\", label=f\"l = {medium_l}\")\n",
    "plt.plot(large_tau_m_run_times.keys(), large_tau_m_run_times.values(), color=\"red\", label=f\"l = {large_l}\")\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Candidates parameter m\")\n",
    "plt.ylabel(\"Run time [s]\")\n",
    "plt.title(\"Run time dependence on m\")\n",
    "\n",
    "plt.savefig(\"results/plots/run_time_random_walker.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments - Monte Carlo Algorithm Pi Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_candidates = list(np.ceil(np.linspace(start=1, stop=300, num=20)))\n",
    "tau_candidates = list(1 / np.logspace(start=1, stop=5, num=10))\n",
    "repetitions = 10\n",
    "compute_experiments = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_experiments:\n",
    "    estimation_error = {}\n",
    "    for c_candidate in c_candidates:\n",
    "        estimation_error[c_candidate] = {}\n",
    "        for tau_candidate in tau_candidates:\n",
    "            estimation_error[c_candidate][tau_candidate] = {}\n",
    "            for i in range(repetitions):\n",
    "                rep_key = f\"rep_{i+1}\"\n",
    "                estimation_error[c_candidate][tau_candidate][rep_key] = {}\n",
    "                print(f\"c={c_candidate}, tau={tau_candidate}, Rep: {i+1}\")\n",
    "\n",
    "                start_time = time.time()\n",
    "                prob_mat_estimated, _ = markov_decision_process.estimate_probability_matrix_pi_method(c=c_candidate, tau=tau_candidate, max_sample_trials=1000)\n",
    "                end_time = time.time()\n",
    "                run_time = round(end_time - start_time, 2)\n",
    "\n",
    "                estimation_error[c_candidate][tau_candidate][rep_key][\"mean\"] = np.mean(np.abs(prob_mat_estimated - prob_mat_ground_truth))\n",
    "                estimation_error[c_candidate][tau_candidate][rep_key][\"sum\"] = np.sum(np.abs(prob_mat_estimated - prob_mat_ground_truth))\n",
    "                estimation_error[c_candidate][tau_candidate][rep_key][\"median\"] = np.median(np.abs(prob_mat_estimated - prob_mat_ground_truth))\n",
    "                estimation_error[c_candidate][tau_candidate][rep_key][\"max\"] = np.max(np.abs(prob_mat_estimated - prob_mat_ground_truth))\n",
    "                estimation_error[c_candidate][tau_candidate][rep_key][\"run_time\"] = run_time\n",
    "\n",
    "                print(f\"Estimation error measures: {estimation_error[c_candidate][tau_candidate][rep_key]} \\n\")\n",
    "\n",
    "    with open(f\"results/estimate_prob_pi_method.pkl\", \"wb\") as file:\n",
    "        pickle.dump(estimation_error, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(f\"results/estimate_prob_pi_method.pkl\", \"rb\") as file:\n",
    "        estimation_error = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimation_error_averaged = {}\n",
    "for c_candidate in c_candidates:\n",
    "    estimation_error_averaged[c_candidate] = {}\n",
    "    for tau_candidate in tau_candidates:\n",
    "        estimation_error_averaged[c_candidate][tau_candidate] = {}\n",
    "\n",
    "        means = np.zeros(repetitions)\n",
    "        sums = np.zeros(repetitions)\n",
    "        medians = np.zeros(repetitions)\n",
    "        maxs = np.zeros(repetitions)\n",
    "        run_times = np.zeros(repetitions)\n",
    "\n",
    "        for i in range(repetitions):\n",
    "            rep_key = f\"rep_{i+1}\"\n",
    "            means[i] = estimation_error[c_candidate][tau_candidate][rep_key][\"mean\"]\n",
    "            sums[i] = estimation_error[c_candidate][tau_candidate][rep_key][\"sum\"]\n",
    "            medians[i] = estimation_error[c_candidate][tau_candidate][rep_key][\"median\"]\n",
    "            maxs[i] = estimation_error[c_candidate][tau_candidate][rep_key][\"max\"]\n",
    "            run_times[i] = estimation_error[c_candidate][tau_candidate][rep_key][\"run_time\"]\n",
    "\n",
    "        estimation_error_averaged[c_candidate][tau_candidate][\"mean\"] = {\"avg\": np.mean(means), \"var\": np.var(means)}\n",
    "        estimation_error_averaged[c_candidate][tau_candidate][\"sum\"] = {\"avg\": np.mean(sums), \"var\": np.var(sums)}\n",
    "        estimation_error_averaged[c_candidate][tau_candidate][\"median\"] = {\"avg\": np.mean(medians), \"var\": np.var(medians)}\n",
    "        estimation_error_averaged[c_candidate][tau_candidate][\"max\"] = {\"avg\": np.mean(maxs), \"var\": np.var(maxs)}\n",
    "        estimation_error_averaged[c_candidate][tau_candidate][\"run_time\"] = {\"avg\": np.mean(run_times), \"var\": np.var(run_times)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_tau = 1e-05\n",
    "medium_tau = 0.001668100537200059\n",
    "large_tau = 0.1\n",
    "\n",
    "small_tau_c_mean_errors = {}\n",
    "medium_tau_c_mean_errors = {}\n",
    "large_tau_c_mean_errors = {}\n",
    "\n",
    "small_tau_c_sum_errors = {}\n",
    "medium_tau_c_sum_errors = {}\n",
    "large_tau_c_sum_errors = {}\n",
    "\n",
    "small_tau_c_max_errors = {}\n",
    "medium_tau_c_max_errors = {}\n",
    "large_tau_c_max_errors = {}\n",
    "\n",
    "small_tau_c_run_times = {}\n",
    "medium_tau_c_run_times = {}\n",
    "large_tau_c_run_times = {}\n",
    "\n",
    "for c in c_candidates:\n",
    "    small_tau_c_mean_errors[c] = estimation_error_averaged[c][small_tau][\"mean\"][\"avg\"]\n",
    "    medium_tau_c_mean_errors[c] = estimation_error_averaged[c][medium_tau][\"mean\"][\"avg\"]\n",
    "    large_tau_c_mean_errors[c] = estimation_error_averaged[c][large_tau][\"mean\"][\"avg\"]\n",
    "\n",
    "    small_tau_c_sum_errors[c] = estimation_error_averaged[c][small_tau][\"sum\"][\"avg\"]\n",
    "    medium_tau_c_sum_errors[c] = estimation_error_averaged[c][medium_tau][\"sum\"][\"avg\"]\n",
    "    large_tau_c_sum_errors[c] = estimation_error_averaged[c][large_tau][\"sum\"][\"avg\"]\n",
    "\n",
    "    small_tau_c_max_errors[c] = estimation_error_averaged[c][small_tau][\"max\"][\"avg\"]\n",
    "    medium_tau_c_max_errors[c] = estimation_error_averaged[c][medium_tau][\"max\"][\"avg\"]\n",
    "    large_tau_c_max_errors[c] = estimation_error_averaged[c][large_tau][\"max\"][\"avg\"]\n",
    "\n",
    "    small_tau_c_run_times[c] = estimation_error_averaged[c][small_tau][\"run_time\"][\"avg\"]\n",
    "    medium_tau_c_run_times[c] = estimation_error_averaged[c][medium_tau][\"run_time\"][\"avg\"]\n",
    "    large_tau_c_run_times[c] = estimation_error_averaged[c][large_tau][\"run_time\"][\"avg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(small_tau_c_mean_errors.keys(), small_tau_c_mean_errors.values(), color=\"blue\", label=f\"tau = {small_tau}\")\n",
    "plt.plot(medium_tau_c_mean_errors.keys(), medium_tau_c_mean_errors.values(), color=\"green\", label=f\"tau = {round(medium_tau,3)}\")\n",
    "plt.plot(large_tau_c_mean_errors.keys(), large_tau_c_mean_errors.values(), color=\"red\", label=f\"tau = {large_tau}\")\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Candidates parameter c\")\n",
    "plt.ylabel(\"MEAN_ERROR\")\n",
    "plt.title(\"Mean error per state transistion probability estimate\")\n",
    "\n",
    "plt.savefig(\"results/plots/mean_error_pi_method.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(small_tau_c_sum_errors.keys(), small_tau_c_sum_errors.values(), color=\"blue\", label=f\"tau = {small_tau}\")\n",
    "plt.plot(medium_tau_c_sum_errors.keys(), medium_tau_c_sum_errors.values(), color=\"green\", label=f\"tau = {round(medium_tau,3)}\")\n",
    "plt.plot(large_tau_c_sum_errors.keys(), large_tau_c_sum_errors.values(), color=\"red\", label=f\"tau = {large_tau}\")\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Candidates parameter c\")\n",
    "plt.ylabel(\"SUM_ERROR\")\n",
    "plt.title(\"Sum of estimation errors over all transitions\")\n",
    "\n",
    "plt.savefig(\"results/plots/sum_error_pi_method.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(small_tau_c_max_errors.keys(), small_tau_c_max_errors.values(), color=\"blue\", label=f\"tau = {small_tau}\")\n",
    "plt.plot(medium_tau_c_max_errors.keys(), medium_tau_c_max_errors.values(), color=\"green\", label=f\"tau = {round(medium_tau,3)}\")\n",
    "plt.plot(large_tau_c_max_errors.keys(), large_tau_c_max_errors.values(), color=\"red\", label=f\"tau = {large_tau}\")\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Candidates parameter c\")\n",
    "plt.ylabel(\"MAX_ERROR\")\n",
    "plt.title(\"Max of estimation errors over all transitions\")\n",
    "\n",
    "plt.savefig(\"results/plots/max_error_pi_method.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(small_tau_c_run_times.keys(), small_tau_c_run_times.values(), color=\"blue\", label=\"tau = 1e-5\")\n",
    "plt.plot(medium_tau_c_run_times.keys(), medium_tau_c_run_times.values(), color=\"green\", label=\"tau = 1e-3\")\n",
    "plt.plot(large_tau_c_run_times.keys(), large_tau_c_run_times.values(), color=\"red\", label=\"tau = 1e-1\")\n",
    "\n",
    "\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Candidates parameter c\")\n",
    "plt.ylabel(\"Run time [s]\")\n",
    "plt.title(\"Run time dependence on c\")\n",
    "\n",
    "plt.savefig(\"results/plots/run_time_pi_method.png\",dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

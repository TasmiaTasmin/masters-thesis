{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming Algorithms - Experiments - Chapter 5 and 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List, Optional\n",
    "from shapely.geometry import Polygon, MultiPolygon, Point\n",
    "\n",
    "from experimental.utils.dynamic_system import DynamicSystem\n",
    "from experimental.utils.markov_decision_process import MarkovDecisionProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build equally-spaced state space partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load baseline partitions from disk, if they already exist\n",
    "if os.path.isfile(\"results/baseline_partitions.pkl\"):\n",
    "    with open(\"results/baseline_partitions.pkl\", \"rb\") as file:\n",
    "        baseline_partitions = pickle.load(file)\n",
    "else:\n",
    "    baseline_partitions = {}\n",
    "\n",
    "baseline_partitions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "m_id = 1\n",
    "equally_spaced_offset_x = np.array([m_id/3, 0])\n",
    "equally_spaced_offset_y = np.array([0, m_id/3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = np.array([0,0])\n",
    "u2 = np.array([0,1])\n",
    "u3 = np.array([1,1])\n",
    "u4 = np.array([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = u1 + equally_spaced_offset_x\n",
    "x2 = u1 + 2*equally_spaced_offset_x\n",
    "x3 = u2 + equally_spaced_offset_x\n",
    "x4 = u2 + 2*equally_spaced_offset_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_vertices = [u1, u2, x3, x1]\n",
    "X1 = MultiPolygon([Polygon(X1_vertices)])\n",
    "\n",
    "X2_vertices = [x3, x4, x2, x1]\n",
    "X2 = MultiPolygon([Polygon(X2_vertices)])\n",
    "\n",
    "X3_vertices = [x4, u3, u4, x2]\n",
    "X3 = MultiPolygon([Polygon(X3_vertices)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiPolygon([Polygon([u1, u2, x3, x1]), Polygon([x3, x4, x2, x1]), Polygon([x4, u3, u4, x2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_partition = [X1, X2, X3]\n",
    "horizontal_partition_vertices = [X1_vertices, X2_vertices, X3_vertices]\n",
    "\n",
    "baseline_partitions[\"horizontal\"] = {}\n",
    "baseline_partitions[\"horizontal\"][\"partition\"] = horizontal_partition\n",
    "baseline_partitions[\"horizontal\"][\"partition_vertices\"] = horizontal_partition_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = u1 + equally_spaced_offset_y\n",
    "y2 = u1 + 2*equally_spaced_offset_y\n",
    "y3 = u4 + equally_spaced_offset_y\n",
    "y4 = u4 + 2*equally_spaced_offset_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1_vertices = [u1, y1, y3, u4]\n",
    "Y1 = MultiPolygon([Polygon(Y1_vertices)])\n",
    "\n",
    "Y2_vertices = [y1, y2, y4, y3]\n",
    "Y2 = MultiPolygon([Polygon(Y2_vertices)])\n",
    "\n",
    "Y3_vertices = [y2, u2, u3, y4]\n",
    "Y3 = MultiPolygon([Polygon(Y3_vertices)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiPolygon([Polygon([u1, y1, y3, u4]), Polygon([y1, y2, y4, y3]), Polygon([y2, u2, u3, y4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical_partition = [Y1, Y2, Y3]\n",
    "vertical_partition_vertices = [Y1_vertices, Y2_vertices, Y3_vertices]\n",
    "\n",
    "baseline_partitions[\"vertical\"] = {}\n",
    "baseline_partitions[\"vertical\"][\"partition\"] = vertical_partition\n",
    "baseline_partitions[\"vertical\"][\"partition_vertices\"] = vertical_partition_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_halved = np.array([m_id/2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1_vertices = [u2, u3, y4, y2]\n",
    "A1 = MultiPolygon([Polygon(A1_vertices)])\n",
    "\n",
    "A2_vertices = [u1, y2, y2+x_halved, u1+x_halved]\n",
    "A2 = MultiPolygon([Polygon(A2_vertices)])\n",
    "\n",
    "A3_vertices = [u1+x_halved, y2+x_halved, y4, u4]\n",
    "A3 = MultiPolygon([Polygon(A3_vertices)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiPolygon([Polygon([u2, u3, y4, y2]), Polygon([u1, y2, y2+x_halved, u1+x_halved]), Polygon([u1+x_halved, y2+x_halved, y4, u4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_partition_1 = [A1, A2, A3]\n",
    "complex_partition_vertices_1 = [A1_vertices, A2_vertices, A3_vertices]\n",
    "\n",
    "baseline_partitions[\"complex_1\"] = {}\n",
    "baseline_partitions[\"complex_1\"][\"partition\"] = complex_partition_1\n",
    "baseline_partitions[\"complex_1\"][\"partition_vertices\"] = complex_partition_vertices_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_halved = np.array([0, m_id/2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1_vertices = [u1, u1+y_halved, x2+y_halved, x2]\n",
    "B1 = MultiPolygon([Polygon(B1_vertices)])\n",
    "\n",
    "B2_vertices = [u1+y_halved, u2, x4, x2+y_halved]\n",
    "B2 = MultiPolygon([Polygon(B2_vertices)])\n",
    "\n",
    "B3_vertices = [x4, u3, u4, x2]\n",
    "B3 = MultiPolygon([Polygon(B3_vertices)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiPolygon([Polygon([u1, u1+y_halved, x2+y_halved, x2]), Polygon([u1+y_halved, u2, x4, x2+y_halved]), Polygon([x4, u3, u4, x2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_partition_2 = [B1, B2, B3]\n",
    "complex_partition_vertices_2 = [B1_vertices, B2_vertices, B3_vertices]\n",
    "\n",
    "baseline_partitions[\"complex_2\"] = {}\n",
    "baseline_partitions[\"complex_2\"][\"partition\"] = complex_partition_2\n",
    "baseline_partitions[\"complex_2\"][\"partition_vertices\"] = complex_partition_vertices_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_partitions.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"results/baseline_partitions.pkl\", \"wb\") as file:\n",
    "    pickle.dump(baseline_partitions, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Policy Evaluation Algorithm with standard example dynamic system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,1], [1,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x: np.array) -> np.array:\n",
    "    x_new = np.dot(A, x) % 1\n",
    "    return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(x: np.array) -> np.array:\n",
    "    return x % 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get eigenvalues and right eigenvectors, i.e. transposed eigenvectors\n",
    "eig_vals, eig_vects = np.linalg.eig(A)\n",
    "# retrieve eigenvectors from right eigenvectors\n",
    "eig_vects = np.transpose(eig_vects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Eigenvalues: {eig_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Eigenvectors: {eig_vects}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = eig_vects[0]\n",
    "v2 = eig_vects[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perp(a) :\n",
    "    b = np.empty_like(a)\n",
    "    b[0] = -a[1]\n",
    "    b[1] = a[0]\n",
    "    return b\n",
    "\n",
    "# line segment a given by endpoints a1, a2\n",
    "# line segment b given by endpoints b1, b2\n",
    "def seg_intersect(a, b) :\n",
    "    a1, a2 = a\n",
    "    b1, b2 = b\n",
    "\n",
    "    da = a2 - a1\n",
    "    db = b2 - b1\n",
    "    dp = a1 - b1\n",
    "    dap = perp(da)\n",
    "    denom = np.dot(dap, db)\n",
    "    num = np.dot(dap, dp)\n",
    "\n",
    "    return (num / denom.astype(float))*db + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = np.array([0,0])\n",
    "u2 = np.array([0,1])\n",
    "u3 = np.array([1,1])\n",
    "u4 = np.array([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu1 = np.array([[0,0], [0,1]])\n",
    "lu2 = np.array([[0,1], [1,1]])\n",
    "lu3 = np.array([[1,1], [1,0]])\n",
    "lu4 = np.array([[1,0], [0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = u1 + (1/v1[0]) * v1\n",
    "p2 = u2 - (1/v2[1]) * v2\n",
    "p3 = u3 - (1/v1[0]) * v1\n",
    "p4 = u4 + (1/v2[1]) * v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_00 = np.array([u1, p1])\n",
    "l_01 = np.array([u2, p2])\n",
    "l_10 = np.array([u4, p4])\n",
    "l_11 = np.array([u3, p3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1a = seg_intersect(l_00, l_01)\n",
    "P1b = seg_intersect(l_10, l_00)\n",
    "\n",
    "P3a = seg_intersect(l_10, l_11)\n",
    "\n",
    "symm_helper_x = seg_intersect(lu2, l_10)\n",
    "symm_helper_y = symm_helper_x - np.array([0,1])\n",
    "symm_helper_l11 = np.array([symm_helper_x, symm_helper_y])\n",
    "\n",
    "p1_symm = symm_helper_y + v2\n",
    "l_10_symm_extension = np.array([symm_helper_y, p1_symm])\n",
    "P3b = seg_intersect(l_10_symm_extension, l_00)\n",
    "l_10_symm_extension = np.array([symm_helper_y, P3b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_00 = np.array([u1, P1b])\n",
    "l_01 = np.array([u2, P1a])\n",
    "l_10 = np.array([u4, p4])\n",
    "l_11 = np.array([u3, P3a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot unit square\n",
    "plt.plot(lu1[:, 0], lu1[:, 1], \"r-\")\n",
    "plt.plot(lu2[:, 0], lu2[:, 1], \"r-\")\n",
    "plt.plot(lu3[:, 0], lu3[:, 1], \"r-\")\n",
    "plt.plot(lu4[:, 0], lu4[:, 1], \"r-\")\n",
    "\n",
    "# step 1: plot l_10 in contracting direction\n",
    "plt.plot(l_10[:, 0], l_10[:, 1], \"b-\")\n",
    "\n",
    "# step 2: plot l_00 and l_11 in expanding directions\n",
    "plt.plot(l_00[:, 0], l_00[:, 1], \"b-\")\n",
    "plt.plot(l_11[:, 0], l_11[:, 1], \"b-\")\n",
    "\n",
    "# step 3: plot l_01 in contracting direction \n",
    "plt.plot(l_01[:, 0], l_01[:, 1], \"b-\")\n",
    "\n",
    "# step 4: plot symmetric extension of l_01 line\n",
    "plt.plot(symm_helper_l11[:, 0], symm_helper_l11[:, 1], \"m--\")\n",
    "plt.plot(l_10_symm_extension[:, 0], l_10_symm_extension[:, 1], \"b-\")\n",
    "\n",
    "# plot intersection points\n",
    "plt.plot(P1a[0], P1a[1], \"bo\")\n",
    "plt.plot(P1b[0], P1b[1], \"ro\")\n",
    "plt.plot(P3a[0], P3a[1], \"go\")\n",
    "plt.plot(P3b[0], P3b[1], \"yo\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1A = Polygon([P1a, u1, u2])\n",
    "P1B = Polygon([P3a, u3, u4])\n",
    "P1 = MultiPolygon([P1A, P1B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P2A = Polygon([P3b, u1, symm_helper_l11[1]])\n",
    "P2B = Polygon([symm_helper_l11[0], u2, P1a, P1b])\n",
    "P2 = MultiPolygon([P2A, P2B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P3A = Polygon([P1b, u4, symm_helper_l11[1], P3b])\n",
    "P3B = Polygon([symm_helper_l11[0], u3, P3a])\n",
    "P3 = MultiPolygon([P3A, P3B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1_vertices = [P1a, u1, u2, P3a]\n",
    "P2_vertices = [P3b, u1, P1a, P1b]\n",
    "P3_vertices = [P1b, u4, P3b, P3a]\n",
    "partition_vertices = [P1_vertices, P2_vertices, P3_vertices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = [P1, P2, P3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiPolygon([P1A, P1B, P2A, P2B, P3A, P3B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1A_phi = Polygon([P1b, u4, u1])\n",
    "P1B_phi = Polygon([u2, u3, phi(P3a)])\n",
    "P1_phi = MultiPolygon([P1A_phi, P1B_phi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symm_helper_x = seg_intersect(lu3, l_00)\n",
    "symm_helper_y = q(symm_helper_x)\n",
    "symm_helper_l00 = np.array([symm_helper_x, symm_helper_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P2A_phi = Polygon([symm_helper_l00[1], phi(P1b), P1a, u1])\n",
    "P2B_phi = Polygon([symm_helper_l00[0], u4, P1b])\n",
    "P2_phi = MultiPolygon([P2A_phi, P2B_phi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P3A_phi = Polygon([phi(P3a), P1a, symm_helper_l00[0], u3])\n",
    "P3B_phi = Polygon([u2, phi(P1b), symm_helper_l00[1]])\n",
    "P3_phi = MultiPolygon([P3A_phi, P3B_phi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MultiPolygon([P1A_phi, P1B_phi, P2A_phi, P2B_phi, P3A_phi, P3B_phi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_phi = [P1_phi, P2_phi, P3_phi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_non_identified(x: np.array) -> np.array:\n",
    "    return np.dot(A, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_phi(x: np.array) -> np.array:\n",
    "    return np.transpose(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_id = 1\n",
    "gamma = 0.8\n",
    "c = 3000\n",
    "tau = 0.0001\n",
    "target_state = np.array([0.5, 0.5])\n",
    "dynamic_system = DynamicSystem(phi_non_identified, d_phi, m_id)\n",
    "markov_decision_process = MarkovDecisionProcess(dynamic_system, partition, partition_vertices=partition_vertices, target_state=target_state, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add markov partition to overall experiment dictionary\n",
    "baseline_partitions[\"markov_1\"] = {}\n",
    "baseline_partitions[\"markov_1\"][\"partition\"] = partition\n",
    "baseline_partitions[\"markov_1\"][\"partition_vertices\"] = partition_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Estimate transition probabilities\")\n",
    "start_time_estimation = time.time()\n",
    "markov_decision_process.estimate_probability_matrix_pi_method(c=c, tau=tau, max_sample_trials=1000)\n",
    "total_time_estimation = time.time() - start_time_estimation\n",
    "print(f\"Transition probability estimation took {round(total_time_estimation, 2)}s\")\n",
    "\n",
    "print(\"Evaluate policy\")\n",
    "epsilon = 10e-6 # 2 * np.finfo(float).eps\n",
    "start_time_evaluation = time.time()\n",
    "V, num_iters, convergence_info = markov_decision_process.policy_evaluation(markov_decision_process.g, epsilon=epsilon)\n",
    "total_time_evaluation = time.time() - start_time_evaluation\n",
    "print(f\"Policy evaluation took {total_time_evaluation}s\")\n",
    "print(f\"Value function: {V}\")\n",
    "print(f\"Number of iterations until convergence: {num_iters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = list(range(1, num_iters))\n",
    "plt.plot(x_values, convergence_info[\"max_dist\"][1:])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"MAX-DIST\")\n",
    "plt.title(\"Maximal convergence distance over iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = list(range(1, num_iters))\n",
    "plt.plot(x_values, convergence_info[\"avg_dist\"][1:])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"L2-DIST\")\n",
    "plt.title(\"L2 convergence distance over iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test policy evaluation for a baseline partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_baseline_partition = baseline_partitions[\"horizontal\"][\"partition\"]\n",
    "test_baseline_partition_vertices = baseline_partitions[\"horizontal\"][\"partition_vertices\"]\n",
    "markov_decision_process = MarkovDecisionProcess(dynamic_system, test_baseline_partition, partition_vertices=test_baseline_partition_vertices, target_state=target_state, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Estimate transition probabilities\")\n",
    "start_time_estimation = time.time()\n",
    "markov_decision_process.estimate_probability_matrix_pi_method(c=c, tau=tau, max_sample_trials=1000)\n",
    "total_time_estimation = time.time() - start_time_estimation\n",
    "print(f\"Transition probability estimation took {round(total_time_estimation, 2)}s\")\n",
    "\n",
    "print(\"Evaluate policy\")\n",
    "epsilon = 10e-6 # 2 * np.finfo(float).eps\n",
    "start_time_evaluation = time.time()\n",
    "V, num_iters, convergence_info = markov_decision_process.policy_evaluation(markov_decision_process.g, epsilon=epsilon)\n",
    "total_time_evaluation = time.time() - start_time_evaluation\n",
    "print(f\"Policy evaluation took {total_time_evaluation}s\")\n",
    "print(f\"Value function: {V}\")\n",
    "print(f\"Number of iterations until convergence: {num_iters}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = list(range(1, num_iters))\n",
    "plt.plot(x_values, convergence_info[\"max_dist\"][1:])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"MAX-DIST\")\n",
    "plt.title(\"Maximal convergence distance over iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = list(range(1, num_iters))\n",
    "plt.plot(x_values, convergence_info[\"avg_dist\"][1:])\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"L2-DIST\")\n",
    "plt.title(\"L2 convergence distance over iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with all partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.8\n",
    "\n",
    "for experiment_run in baseline_partitions.keys():\n",
    "    print(\"\\n---------------------------------------\\n\")\n",
    "    print(f\"Experiment run with {experiment_run} partition\")\n",
    "\n",
    "    partition = baseline_partitions[experiment_run][\"partition\"]\n",
    "    partition_vertices = baseline_partitions[experiment_run][\"partition_vertices\"]\n",
    "    markov_decision_process = MarkovDecisionProcess(dynamic_system, partition, partition_vertices=partition_vertices, target_state=target_state, gamma=gamma)\n",
    "\n",
    "    print(\"Estimate transition probabilities\")\n",
    "    start_time_estimation = time.time()\n",
    "    markov_decision_process.estimate_probability_matrix_pi_method(c=c, tau=tau, max_sample_trials=1000)\n",
    "    total_time_estimation = time.time() - start_time_estimation\n",
    "    print(f\"Transition probability estimation took {round(total_time_estimation, 2)}s\")\n",
    "\n",
    "    print(\"Evaluate policy\")\n",
    "    epsilon = 10e-6 # 2 * np.finfo(float).eps\n",
    "    start_time_evaluation = time.time()\n",
    "    V, num_iters, convergence_info = markov_decision_process.policy_evaluation(markov_decision_process.g, epsilon=epsilon)\n",
    "    total_time_evaluation = time.time() - start_time_evaluation\n",
    "    print(f\"Policy evaluation took {total_time_evaluation}s\")\n",
    "    print(f\"Value function: {V}\")\n",
    "    print(f\"Number of iterations until convergence: {num_iters}\")\n",
    "\n",
    "    x_values = list(range(1, num_iters))\n",
    "    plt.plot(x_values, convergence_info[\"max_dist\"][1:])\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"MAX-DIST\")\n",
    "    plt.title(\"Maximal convergence distance over iterations\")\n",
    "    plt.show()\n",
    "\n",
    "    x_values = list(range(1, num_iters))\n",
    "    plt.plot(x_values, convergence_info[\"avg_dist\"][1:])\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"L2-DIST\")\n",
    "    plt.title(\"L2 convergence distance over iterations\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
